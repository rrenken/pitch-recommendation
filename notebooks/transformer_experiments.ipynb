{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from embeddings import PitchEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Example usage:\n",
    "# Suppose you have 100 continuous fields and 13 categorical fields.\n",
    "# For demonstration, here we use 4 categorical features as an example.\n",
    "\n",
    "continuous_dim = 100\n",
    "\n",
    "# Dictionary for categorical variables:\n",
    "# Keys are the feature names, and for each you specify the number of unique categories and desired embedding dimension.\n",
    "categorical_info = {\n",
    "    'pitcher_id': {'num_categories': 500, 'embedding_dim': 32},\n",
    "    'pitch_type': {'num_categories': 10, 'embedding_dim': 16},\n",
    "    'batter_side': {'num_categories': 3, 'embedding_dim': 8},\n",
    "    'game_situation': {'num_categories': 20, 'embedding_dim': 16},\n",
    "    # ... add the rest as needed to reach a total of 13 categorical features.\n",
    "}\n",
    "\n",
    "output_dim = 256  # Final token embedding dimension\n",
    "\n",
    "# Instantiate the embedding model\n",
    "pitch_embedding_model = PitchEmbedding(continuous_dim, categorical_info, output_dim)\n",
    "\n",
    "# Create dummy data for a batch of 32 pitches\n",
    "batch_size = 32\n",
    "continuous_inputs = torch.randn(batch_size, continuous_dim)\n",
    "\n",
    "categorical_inputs = {\n",
    "    'pitcher_id': torch.randint(0, 500, (batch_size,)),\n",
    "    'pitch_type': torch.randint(0, 10, (batch_size,)),\n",
    "    'batter_side': torch.randint(0, 3, (batch_size,)),\n",
    "    'game_situation': torch.randint(0, 20, (batch_size,))\n",
    "    # ... ensure you provide inputs for all categorical features defined in categorical_info.\n",
    "}\n",
    "\n",
    "# Generate the embeddings\n",
    "embeddings = pitch_embedding_model(continuous_inputs, categorical_inputs)\n",
    "print(\"Embedding shape:\", embeddings.shape)  # Expected output: (32, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.embeddings import PitchEmbedding\n",
    "\n",
    "# 1. ADD AT-BAT ID AS A CATEGORICAL FEATURE\n",
    "categorical_info = {\n",
    "    'pitch_type': {'num_categories': 10, 'embedding_dim': 16},\n",
    "    'at_bat_id': {'num_categories': 10000, 'embedding_dim': 32},  # Unique ID for each at-bat\n",
    "    'pitch_number_in_at_bat': {'num_categories': 20, 'embedding_dim': 8},  # Position in sequence\n",
    "    # ... other categorical features\n",
    "}\n",
    "\n",
    "# 2. CREATE EMBEDDING MODEL\n",
    "pitch_embedding_model = PitchEmbedding(continuous_dim, categorical_info, output_dim)\n",
    "\n",
    "# 3. PREPARE FLAT BATCH OF PITCHES WITH AT-BAT CONTEXT\n",
    "batch_size = 128  # Now this is just \"number of pitches\" (not at-bats)\n",
    "\n",
    "# Each pitch now carries its at-bat context with it\n",
    "continuous_inputs = torch.randn(batch_size, continuous_dim)\n",
    "categorical_inputs = {\n",
    "    'pitch_type': torch.randint(0, 10, (batch_size,)),\n",
    "    'at_bat_id': torch.randint(0, 10000, (batch_size,)),  # Pitches from same at-bat share this ID\n",
    "    'pitch_number_in_at_bat': torch.randint(0, 20, (batch_size,)),  # Position in the at-bat\n",
    "    # ... other categorical inputs\n",
    "}\n",
    "\n",
    "# 4. GENERATE EMBEDDINGS\n",
    "pitch_embeddings = pitch_embedding_model(continuous_inputs, categorical_inputs)\n",
    "\n",
    "# 5. CREATE AT-BAT SEQUENCES FOR TRANSFORMER\n",
    "# Group by at-bat ID\n",
    "unique_at_bats = categorical_inputs['at_bat_id'].unique()\n",
    "sequences = []\n",
    "\n",
    "for at_bat_id in unique_at_bats[:16]:  # Process 16 at-bats\n",
    "    # Find all pitches for this at-bat\n",
    "    mask = categorical_inputs['at_bat_id'] == at_bat_id\n",
    "    # Get embeddings for those pitches\n",
    "    at_bat_pitches = pitch_embeddings[mask]\n",
    "    # Sort by position in at-bat\n",
    "    positions = categorical_inputs['pitch_number_in_at_bat'][mask]\n",
    "    _, indices = positions.sort()\n",
    "    sorted_pitches = at_bat_pitches[indices]\n",
    "    sequences.append(sorted_pitches)\n",
    "\n",
    "# Now feed these sequences to your transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from embeddings import PitchEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in file: 3073583\n",
      "Processed 1,000,000 lines...\n",
      "Processed 2,000,000 lines...\n",
      "Processed 3,000,000 lines...\n",
      "Sampled 9935 lines from 3,073,583 total\n",
      "Successfully loaded 9935 rows\n"
     ]
    }
   ],
   "source": [
    "# Memory-efficient random sampling from large file\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "sample_size = 10000\n",
    "input_file = '../data/processed/pitcher_final_21-24.csv'\n",
    "output_file = '../data/processed/pitcher_test_sample.csv'\n",
    "\n",
    "# Count total lines first (optional but helps with progress reporting)\n",
    "with open(input_file, 'r') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total lines in file: {total_lines}\")\n",
    "\n",
    "# Calculate sampling probability\n",
    "sampling_probability = sample_size / (total_lines - 1)  # Exclude header\n",
    "\n",
    "# Perform reservoir sampling\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    # Copy header\n",
    "    header = next(infile)\n",
    "    outfile.write(header)\n",
    "    \n",
    "    # Process remaining lines with sampling\n",
    "    lines_sampled = 0\n",
    "    for i, line in enumerate(infile):\n",
    "        if random.random() < sampling_probability:\n",
    "            outfile.write(line)\n",
    "            lines_sampled += 1\n",
    "            \n",
    "        # Report progress every million lines\n",
    "        if (i+1) % 1000000 == 0:\n",
    "            print(f\"Processed {i+1:,} lines...\")\n",
    "            \n",
    "    print(f\"Sampled {lines_sampled} lines from {total_lines:,} total\")\n",
    "\n",
    "# Load the much smaller sample file\n",
    "df = pd.read_csv(output_file)\n",
    "print(f\"Successfully loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Normalizing continuous features...\n",
      "Converting categorical features to indices...\n",
      "pitch_type: 18 categories, 16 dimensions\n",
      "batter: 1006 categories, 16 dimensions\n",
      "pitcher: 1217 categories, 16 dimensions\n",
      "events: 20 categories, 12 dimensions\n",
      "description: 12 categories, 2 dimensions\n",
      "zone: 14 categories, 6 dimensions\n",
      "game_type: 6 categories, 4 dimensions\n",
      "stand: 2 categories, 4 dimensions\n",
      "p_throws: 2 categories, 4 dimensions\n",
      "home_team: 30 categories, 8 dimensions\n",
      "away_team: 30 categories, 8 dimensions\n",
      "hit_location: 10 categories, 6 dimensions\n",
      "bb_type: 5 categories, 8 dimensions\n",
      "balls: 4 categories, 4 dimensions\n",
      "strikes: 3 categories, 4 dimensions\n",
      "game_year: 4 categories, 4 dimensions\n",
      "outs_when_up: 3 categories, 8 dimensions\n",
      "inning: 13 categories, 16 dimensions\n",
      "inning_topbot: 2 categories, 2 dimensions\n",
      "game_pk: 6459 categories, 16 dimensions\n",
      "fielder_2: 217 categories, 2 dimensions\n",
      "fielder_3: 373 categories, 2 dimensions\n",
      "fielder_4: 395 categories, 2 dimensions\n",
      "fielder_5: 416 categories, 2 dimensions\n",
      "fielder_6: 304 categories, 2 dimensions\n",
      "fielder_7: 519 categories, 2 dimensions\n",
      "fielder_8: 367 categories, 2 dimensions\n",
      "fielder_9: 486 categories, 2 dimensions\n",
      "pitch_number: 11 categories, 12 dimensions\n",
      "launch_speed_angle: 7 categories, 12 dimensions\n",
      "if_fielding_alignment: 5 categories, 4 dimensions\n",
      "of_fielding_alignment: 4 categories, 4 dimensions\n",
      "n_thruorder_pitcher: 4 categories, 12 dimensions\n",
      "n_priorpa_thisgame_player_at_bat: 6 categories, 12 dimensions\n",
      "pitch_name: 18 categories, 2 dimensions\n",
      "at_bat_id: 9880 categories, 16 dimensions\n",
      "month: 8 categories, 6 dimensions\n",
      "score_diff: 35 categories, 8 dimensions\n",
      "risp: 2 categories, 12 dimensions\n",
      "clutch: 2 categories, 12 dimensions\n",
      "blowout: 2 categories, 4 dimensions\n",
      "post_allstar_break: 2 categories, 4 dimensions\n",
      "Creating tensors...\n",
      "Creating embedding model...\n",
      "Generating embeddings...\n",
      "Created embeddings with shape: torch.Size([9935, 128])\n",
      "Organizing into at-bat sequences...\n",
      "Total at-bats: 9880\n",
      "Processed 5000 at-bat sequences\n",
      "Average pitches per at-bat: 1.01\n",
      "Maximum sequence length: 2\n",
      "Padding sequences...\n",
      "Final tensor shape: torch.Size([5000, 2, 128])\n",
      "Attention mask shape: torch.Size([5000, 2])\n",
      "Embeddings saved and ready for transformer training!\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD PROCESSED DATA\n",
    "print(\"Loading processed data...\")\n",
    "# Use your engineered dataset\n",
    "#df = pd.read_csv('../data/processed/pitcher_final_21-24.csv')\n",
    "\n",
    "# 2. DEFINE CONTINUOUS & CATEGORICAL FEATURES\n",
    "continuous_features = [\n",
    "    'release_speed', 'release_pos_x', 'release_pos_z', \n",
    "    'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'hc_x', 'hc_y',\n",
    "    'vx0', 'vy0', 'vz0', 'ax', 'ay', \n",
    "    'az', 'sz_top', 'sz_bot', 'hit_distance_sc', \n",
    "    'launch_speed', 'launch_angle', 'effective_speed', \n",
    "    'release_spin_rate', 'release_extension', \n",
    "    'release_pos_y', 'estimated_ba_using_speedangle',\n",
    "    'estimated_woba_using_speedangle', 'woba_value',\n",
    "    'woba_denom', 'babip_value', 'iso_value', 'spin_axis',\n",
    "    'delta_home_win_exp', 'delta_run_exp', 'bat_speed' ,\n",
    "    'swing_length', 'estimated_slg_using_speedangle',\n",
    "    'delta_pitcher_run_exp', 'hyper_speed',\n",
    "    'bat_win_exp',\n",
    "    'pitcher_days_since_prev_game', \n",
    "    'batter_days_since_prev_game',\n",
    "    'pitcher_days_until_next_game',\n",
    "    'batter_days_until_next_game',\n",
    "    'api_break_z_with_gravity',\n",
    "    'api_break_x_arm',\n",
    "    'api_break_x_batter_in',\n",
    "    'arm_angle', 'home_win_exp',\n",
    "    'on_3b', 'on_2b',\n",
    "    'on_1b',\n",
    "\n",
    "    'at_bat_number', 'bat_score', 'fld_score', 'age_pit', 'age_bat'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'pitch_type', 'batter', 'pitcher', 'events', 'description', 'zone', \n",
    "    'game_type', 'stand', 'p_throws', 'home_team', 'away_team', \n",
    "    ############'result_type',\n",
    "    'hit_location', 'bb_type', 'balls', 'strikes', 'game_year',\n",
    "    'outs_when_up', 'inning', 'inning_topbot', 'game_pk',\n",
    "    'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6',\n",
    "    'fielder_7', 'fielder_8', 'fielder_9', \n",
    "    #'at_bat_number', \n",
    "    'pitch_number',\n",
    "    'launch_speed_angle', \n",
    "    #'home_score', 'away_score', \n",
    "    #'bat_score',\n",
    "    #'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', \n",
    "    'if_fielding_alignment', 'of_fielding_alignment',\n",
    "    #'age_pit_legacy', 'age_bat_legacy', \n",
    "    #'age_pit', 'age_bat',\n",
    "    'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat',\n",
    "    'pitch_name',\n",
    "\n",
    "    'at_bat_id', 'month','score_diff', 'risp', 'clutch', 'blowout', 'post_allstar_break'\n",
    "]\n",
    "\n",
    "\n",
    "# 3. NORMALIZE CONTINUOUS FEATURES\n",
    "print(\"Normalizing continuous features...\")\n",
    "scaler = StandardScaler()\n",
    "df_cont = df[continuous_features].copy()\n",
    "# Handle any remaining NaNs\n",
    "df_cont = df_cont.fillna(0)\n",
    "df_cont_scaled = scaler.fit_transform(df_cont)\n",
    "\n",
    "# 4. CREATE CATEGORY MAPPINGS & CONVERT TO INDICES\n",
    "print(\"Converting categorical features to indices...\")\n",
    "category_maps = {}\n",
    "cat_data = {}\n",
    "\n",
    "# Define custom embedding dimensions for important features\n",
    "# Format: 'feature_name': desired_embedding_dimension\n",
    "custom_embedding_dims = {\n",
    "    'pitch_type': 16, \n",
    "    'batter': 16, \n",
    "    'pitcher': 16, \n",
    "    'events': 12, \n",
    "    #'description', \n",
    "    'zone': 6, \n",
    "    'game_type': 4, \n",
    "    'stand': 4, \n",
    "    'p_throws': 4, \n",
    "    'home_team': 8, \n",
    "    'away_team': 8, \n",
    "    ##########'result_type': 4,\n",
    "    'hit_location': 6, \n",
    "    'bb_type': 8, \n",
    "    'balls': 4, \n",
    "    'strikes': 4, \n",
    "    'game_year': 4,\n",
    "    'outs_when_up': 8, \n",
    "    'inning': 16, \n",
    "    'inning_topbot': 2, \n",
    "    'game_pk': 16,\n",
    "    #'fielder_2':, \n",
    "    #'fielder_3':, \n",
    "    #'fielder_4':, \n",
    "    #'fielder_5':, \n",
    "    #'fielder_6':,\n",
    "    #'fielder_7':, \n",
    "    #'fielder_8':, \n",
    "    #'fielder_9':, \n",
    "    ####'at_bat_number': 12, \n",
    "    'pitch_number': 12,\n",
    "    'launch_speed_angle': 12, \n",
    "    #'home_score', \n",
    "    #'away_score', \n",
    "    ####'bat_score': 16,\n",
    "    ####'fld_score': 16, \n",
    "    #'post_away_score', \n",
    "    #'post_home_score', \n",
    "    #'post_bat_score',\n",
    "    #'post_fld_score', \n",
    "    'if_fielding_alignment': 4, \n",
    "    'of_fielding_alignment': 4,\n",
    "    #'age_pit_legacy', \n",
    "    #'age_bat_legacy', \n",
    "    ####'age_pit': 8, \n",
    "    ####'age_bat': 8,\n",
    "    'n_thruorder_pitcher': 12, \n",
    "    'n_priorpa_thisgame_player_at_bat': 12,\n",
    "    #'pitch_name',\n",
    "\n",
    "    'at_bat_id': 16, \n",
    "    'month': 6,\n",
    "    'score_diff': 8, \n",
    "    'risp': 12, \n",
    "    'clutch': 12,\n",
    "    'blowout': 4, \n",
    "    'post_allstar_break': 4\n",
    "}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Create a mapping from category values to indices\n",
    "    unique_values = df[feature].dropna().unique()\n",
    "    category_maps[feature] = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    \n",
    "    # Use custom dimension if specified, otherwise use heuristic\n",
    "    if feature in custom_embedding_dims:\n",
    "        embedding_dim = custom_embedding_dims[feature]\n",
    "    else:\n",
    "        # Fallback to heuristic\n",
    "        #embedding_dim = min(50, max(4, int(np.sqrt(len(unique_values)) * 2)))\n",
    "        embedding_dim = 2\n",
    "    \n",
    "    # Store category counts and embedding dimensions\n",
    "    cat_data[feature] = {\n",
    "        'num_categories': len(unique_values) + 1,  # +1 for unknown/padding\n",
    "        'embedding_dim': embedding_dim\n",
    "    }\n",
    "    \n",
    "    # Print some info\n",
    "    print(f\"{feature}: {len(unique_values)} categories, {cat_data[feature]['embedding_dim']} dimensions\")\n",
    "\n",
    "\n",
    "\n",
    "# 5. CONVERT TO PYTORCH TENSORS\n",
    "print(\"Creating tensors...\")\n",
    "# Create a tensor for all continuous features\n",
    "continuous_tensor = torch.tensor(df_cont_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create tensors for categorical features\n",
    "categorical_tensors = {}\n",
    "for feature in categorical_features:\n",
    "    # Map values to indices, using 0 for NaN\n",
    "    indices = [category_maps[feature].get(val, 0) for val in df[feature].fillna('unknown')]\n",
    "    categorical_tensors[feature] = torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "# 6. DEFINE MODEL PARAMETERS\n",
    "continuous_dim = len(continuous_features)\n",
    "#output_dim = 256  # Final embedding dimension\n",
    "output_dim = 128  # Final embedding dimension (smaller for prototype)\n",
    "\n",
    "# 7. CREATE EMBEDDING MODEL\n",
    "print(\"Creating embedding model...\")\n",
    "embedding_model = PitchEmbedding(continuous_dim, cat_data, output_dim)\n",
    "\n",
    "# 8. GENERATE EMBEDDINGS\n",
    "print(\"Generating embeddings...\")\n",
    "with torch.no_grad():  # No need for gradients during inference\n",
    "    pitch_embeddings = embedding_model(continuous_tensor, categorical_tensors)\n",
    "\n",
    "print(f\"Created embeddings with shape: {pitch_embeddings.shape}\")\n",
    "\n",
    "# 9. ORGANIZE INTO AT-BAT SEQUENCES\n",
    "print(\"Organizing into at-bat sequences...\")\n",
    "# Group by at_bat_id\n",
    "unique_at_bats = df['at_bat_id'].unique()\n",
    "print(f\"Total at-bats: {len(unique_at_bats)}\")\n",
    "\n",
    "# Store atbat sequences and their lengths\n",
    "atbat_sequences = []\n",
    "atbat_lengths = []\n",
    "max_seq_len = 0\n",
    "\n",
    "# Process a subset for demonstration (adjust as needed)\n",
    "#sample_at_bats = unique_at_bats[:1000]     #.. (try with only 1000 at-bats for testing)\n",
    "sample_at_bats = unique_at_bats[:5000]    #.. (try it with more data for more testing)\n",
    "# sample_at_bats = unique_at_bats           .. (use all data for production)\n",
    "\n",
    "\n",
    "for at_bat_id in sample_at_bats:\n",
    "    # Get indices for this at-bat\n",
    "    indices = df[df['at_bat_id'] == at_bat_id].index\n",
    "    \n",
    "    # Get embeddings for these pitches\n",
    "    at_bat_embeddings = pitch_embeddings[indices]\n",
    "    \n",
    "    # Update max sequence length\n",
    "    max_seq_len = max(max_seq_len, len(indices))\n",
    "    \n",
    "    # Store sequence and length\n",
    "    atbat_sequences.append(at_bat_embeddings)\n",
    "    atbat_lengths.append(len(indices))\n",
    "\n",
    "print(f\"Processed {len(atbat_sequences)} at-bat sequences\")\n",
    "print(f\"Average pitches per at-bat: {np.mean(atbat_lengths):.2f}\")\n",
    "print(f\"Maximum sequence length: {max_seq_len}\")\n",
    "\n",
    "# 10. PAD SEQUENCES FOR BATCH PROCESSING\n",
    "print(\"Padding sequences...\")\n",
    "padded_sequences = []\n",
    "attention_mask = []\n",
    "\n",
    "for seq in atbat_sequences:\n",
    "    seq_len = seq.shape[0]\n",
    "    \n",
    "    # Create padded sequence\n",
    "    padded = torch.zeros(max_seq_len, output_dim)\n",
    "    padded[:seq_len] = seq\n",
    "    \n",
    "    # Create mask (1 for real tokens, 0 for padding)\n",
    "    mask = torch.zeros(max_seq_len)\n",
    "    mask[:seq_len] = 1\n",
    "    \n",
    "    padded_sequences.append(padded)\n",
    "    attention_mask.append(mask)\n",
    "\n",
    "# Stack into tensors\n",
    "padded_tensor = torch.stack(padded_sequences)\n",
    "attention_mask = torch.stack(attention_mask).bool()\n",
    "\n",
    "print(f\"Final tensor shape: {padded_tensor.shape}\")\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "\n",
    "# 11. SAVE FOR LATER USE\n",
    "torch.save({\n",
    "    'embeddings': padded_tensor,\n",
    "    'attention_mask': attention_mask,\n",
    "    'scaler': scaler,\n",
    "    'category_maps': category_maps\n",
    "}, '../data/embeddings/pitch_embeddings_test1000.pt')\n",
    "\n",
    "print(\"Embeddings saved and ready for transformer training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_baseball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
