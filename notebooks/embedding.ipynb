{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from embeddings import PitchEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce MX250\n",
      "Memory: 2.15 GB\n"
     ]
    }
   ],
   "source": [
    "# Check and use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample of rows to test PitchEmbedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in file: 3073583\n",
      "Processed 1,000,000 lines...\n",
      "Processed 2,000,000 lines...\n",
      "Processed 3,000,000 lines...\n",
      "Sampled 500788 lines from 3,073,583 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanr\\AppData\\Local\\Temp\\ipykernel_15640\\295004641.py:42: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(output_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 500788 rows\n"
     ]
    }
   ],
   "source": [
    "# Memory-efficient random sampling from large file\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "sample_size = 500000\n",
    "input_file = '../data/processed/pitcher_final_21-24.csv'\n",
    "output_file = '../data/processed/pitcher_test_sample.csv'\n",
    "\n",
    "# Count total lines first (optional but helps with progress reporting)\n",
    "with open(input_file, 'r') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total lines in file: {total_lines}\")\n",
    "\n",
    "# Calculate sampling probability\n",
    "sampling_probability = sample_size / (total_lines - 1)  # Exclude header\n",
    "\n",
    "# Perform reservoir sampling\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    # Copy header\n",
    "    header = next(infile)\n",
    "    outfile.write(header)\n",
    "    \n",
    "    # Process remaining lines with sampling\n",
    "    lines_sampled = 0\n",
    "    for i, line in enumerate(infile):\n",
    "        if random.random() < sampling_probability:\n",
    "            outfile.write(line)\n",
    "            lines_sampled += 1\n",
    "            \n",
    "        # Report progress every million lines\n",
    "        if (i+1) % 1000000 == 0:\n",
    "            print(f\"Processed {i+1:,} lines...\")\n",
    "            \n",
    "    print(f\"Sampled {lines_sampled} lines from {total_lines:,} total\")\n",
    "\n",
    "# Load the much smaller sample file\n",
    "df = pd.read_csv(output_file)\n",
    "print(f\"Successfully loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Read your CSV file\n",
    "#df = pd.read_csv('../data/processed/pitcher_final_21-24.csv')\n",
    "\n",
    "# Convert problematic columns to appropriate types\n",
    "# Convert 'zone' column to numeric, handling any string values\n",
    "df['zone'] = pd.to_numeric(df['zone'], errors='coerce')\n",
    "\n",
    "# Handle other potential problematic columns\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "\t# Try to convert string representations of numbers to actual numeric values\n",
    "\ttry:\n",
    "\t\tdf[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "# Save as Parquet (install pyarrow if needed: pip install pyarrow)\n",
    "df.to_parquet('../data/processed/pitcher_final_21-24.parquet', engine='pyarrow')\n",
    "\n",
    "print(\"Conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Normalizing continuous features...\n",
      "Converting categorical features to indices...\n",
      "pitch_type: 0 categories, 16 dimensions\n",
      "batter: 2481 categories, 16 dimensions\n",
      "pitcher: 2218 categories, 16 dimensions\n",
      "events: 0 categories, 12 dimensions\n",
      "zone: 13 categories, 6 dimensions\n",
      "game_type: 0 categories, 4 dimensions\n",
      "stand: 0 categories, 4 dimensions\n",
      "p_throws: 0 categories, 4 dimensions\n",
      "home_team: 0 categories, 8 dimensions\n",
      "away_team: 0 categories, 8 dimensions\n",
      "result_type: 0 categories, 4 dimensions\n",
      "hit_location: 9 categories, 6 dimensions\n",
      "bb_type: 0 categories, 8 dimensions\n",
      "balls: 4 categories, 4 dimensions\n",
      "strikes: 3 categories, 4 dimensions\n",
      "game_year: 4 categories, 4 dimensions\n",
      "outs_when_up: 3 categories, 8 dimensions\n",
      "inning: 18 categories, 16 dimensions\n",
      "inning_topbot: 0 categories, 2 dimensions\n",
      "game_pk: 10705 categories, 16 dimensions\n",
      "fielder_2: 363 categories, 2 dimensions\n",
      "fielder_3: 656 categories, 2 dimensions\n",
      "fielder_4: 714 categories, 2 dimensions\n",
      "fielder_5: 717 categories, 2 dimensions\n",
      "fielder_6: 550 categories, 2 dimensions\n",
      "fielder_7: 947 categories, 2 dimensions\n",
      "fielder_8: 640 categories, 2 dimensions\n",
      "fielder_9: 868 categories, 2 dimensions\n",
      "pitch_number: 16 categories, 12 dimensions\n",
      "launch_speed_angle: 6 categories, 12 dimensions\n",
      "if_fielding_alignment: 0 categories, 4 dimensions\n",
      "of_fielding_alignment: 0 categories, 4 dimensions\n",
      "n_thruorder_pitcher: 4 categories, 12 dimensions\n",
      "n_priorpa_thisgame_player_at_bat: 8 categories, 12 dimensions\n",
      "on_1b: 1859 categories, 4 dimensions\n",
      "on_2b: 1615 categories, 4 dimensions\n",
      "on_3b: 1382 categories, 4 dimensions\n",
      "at_bat_id: 373071 categories, 16 dimensions\n",
      "month: 8 categories, 6 dimensions\n",
      "score_diff: 51 categories, 8 dimensions\n",
      "risp: 2 categories, 12 dimensions\n",
      "clutch: 2 categories, 12 dimensions\n",
      "blowout: 2 categories, 4 dimensions\n",
      "post_allstar_break: 2 categories, 4 dimensions\n",
      "Creating tensors...\n",
      "Creating embedding model...\n",
      "Generating embeddings...\n",
      "Created embeddings with shape: torch.Size([500788, 128])\n",
      "Organizing into at-bat sequences...\n",
      "Total at-bats: 373071\n",
      "Processed 373071 at-bat sequences\n",
      "Average pitches per at-bat: 1.34\n",
      "Maximum sequence length: 7\n",
      "Padding sequences...\n",
      "Final tensor shape: torch.Size([373071, 7, 128])\n",
      "Attention mask shape: torch.Size([373071, 7])\n",
      "Embeddings saved and ready for transformer training!\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD PROCESSED DATA\n",
    "print(\"Loading processed data...\")\n",
    "# Use your engineered dataset\n",
    "#df = pd.read_csv('../data/processed/pitcher_final_21-24.parquet')\n",
    "df = pd.read_parquet('../data/processed/pitcher_final_21-24.parquet')\n",
    "\n",
    "# 2. DEFINE CONTINUOUS & CATEGORICAL FEATURES\n",
    "continuous_features = [\n",
    "    'release_speed', 'release_pos_x', 'release_pos_z', \n",
    "    'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'hc_x', 'hc_y',\n",
    "    'vx0', 'vy0', 'vz0', 'ax', 'ay', \n",
    "    'az', 'sz_top', 'sz_bot', 'hit_distance_sc', \n",
    "    'launch_speed', 'launch_angle', 'effective_speed', \n",
    "    'release_spin_rate', 'release_extension', \n",
    "    'release_pos_y', 'estimated_ba_using_speedangle',\n",
    "    'estimated_woba_using_speedangle', 'woba_value',\n",
    "    'woba_denom', 'babip_value', 'iso_value', 'spin_axis',\n",
    "    'delta_home_win_exp', 'delta_run_exp', 'bat_speed' ,\n",
    "    'swing_length', 'estimated_slg_using_speedangle',\n",
    "    'delta_pitcher_run_exp', 'hyper_speed',\n",
    "    'bat_win_exp',\n",
    "    'pitcher_days_since_prev_game', \n",
    "    'batter_days_since_prev_game',\n",
    "    'pitcher_days_until_next_game',\n",
    "    'batter_days_until_next_game',\n",
    "    'api_break_z_with_gravity',\n",
    "    'api_break_x_arm',\n",
    "    'api_break_x_batter_in',\n",
    "    'arm_angle', 'home_win_exp',\n",
    "\n",
    "    'at_bat_number', 'bat_score', 'fld_score', 'age_pit', 'age_bat'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'pitch_type', 'batter', 'pitcher', 'events', \n",
    "    #'description', \n",
    "    'zone', \n",
    "    'game_type', 'stand', 'p_throws', 'home_team', 'away_team', \n",
    "    'result_type',\n",
    "    'hit_location', 'bb_type', 'balls', 'strikes', 'game_year',\n",
    "    'outs_when_up', 'inning', 'inning_topbot', 'game_pk',\n",
    "    'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6',\n",
    "    'fielder_7', 'fielder_8', 'fielder_9', \n",
    "    #'at_bat_number', \n",
    "    'pitch_number',\n",
    "    'launch_speed_angle', \n",
    "    #'home_score', 'away_score', \n",
    "    #'bat_score',\n",
    "    #'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', \n",
    "    'if_fielding_alignment', 'of_fielding_alignment',\n",
    "    #'age_pit_legacy', 'age_bat_legacy', \n",
    "    #'age_pit', 'age_bat',\n",
    "    'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat',\n",
    "    #'pitch_name',\n",
    "    'on_1b', 'on_2b', 'on_3b',\n",
    "\n",
    "    'at_bat_id', 'month','score_diff', 'risp', 'clutch', 'blowout', 'post_allstar_break'\n",
    "]\n",
    "\n",
    "\n",
    "# 3. NORMALIZE CONTINUOUS FEATURES\n",
    "print(\"Normalizing continuous features...\")\n",
    "scaler = StandardScaler()\n",
    "df_cont = df[continuous_features].copy()\n",
    "# Handle any remaining NaNs\n",
    "df_cont = df_cont.fillna(0)\n",
    "df_cont_scaled = scaler.fit_transform(df_cont)\n",
    "\n",
    "# 4. CREATE CATEGORY MAPPINGS & CONVERT TO INDICES\n",
    "print(\"Converting categorical features to indices...\")\n",
    "category_maps = {}\n",
    "cat_data = {}\n",
    "\n",
    "# Define custom embedding dimensions for important features\n",
    "# Format: 'feature_name': desired_embedding_dimension\n",
    "custom_embedding_dims = {\n",
    "    'pitch_type': 16, \n",
    "    'batter': 16, \n",
    "    'pitcher': 16, \n",
    "    'events': 12, \n",
    "    #'description', \n",
    "    'zone': 6, \n",
    "    'game_type': 4, \n",
    "    'stand': 4, \n",
    "    'p_throws': 4, \n",
    "    'home_team': 8, \n",
    "    'away_team': 8, \n",
    "    'result_type': 4,\n",
    "    'hit_location': 6, \n",
    "    'bb_type': 8, \n",
    "    'balls': 4, \n",
    "    'strikes': 4, \n",
    "    'game_year': 4,\n",
    "    'outs_when_up': 8, \n",
    "    'inning': 16, \n",
    "    'inning_topbot': 2, \n",
    "    'game_pk': 16,\n",
    "    #'fielder_2':, \n",
    "    #'fielder_3':, \n",
    "    #'fielder_4':, \n",
    "    #'fielder_5':, \n",
    "    #'fielder_6':,\n",
    "    #'fielder_7':, \n",
    "    #'fielder_8':, \n",
    "    #'fielder_9':, \n",
    "    ####'at_bat_number': 12, \n",
    "    'pitch_number': 12,\n",
    "    'launch_speed_angle': 12, \n",
    "    #'home_score', \n",
    "    #'away_score', \n",
    "    ####'bat_score': 16,\n",
    "    ####'fld_score': 16, \n",
    "    #'post_away_score', \n",
    "    #'post_home_score', \n",
    "    #'post_bat_score',\n",
    "    #'post_fld_score', \n",
    "    'if_fielding_alignment': 4, \n",
    "    'of_fielding_alignment': 4,\n",
    "    #'age_pit_legacy', \n",
    "    #'age_bat_legacy', \n",
    "    ####'age_pit': 8, \n",
    "    ####'age_bat': 8,\n",
    "    'n_thruorder_pitcher': 12, \n",
    "    'n_priorpa_thisgame_player_at_bat': 12,\n",
    "    #'pitch_name',\n",
    "    \n",
    "    'on_1b': 4,\n",
    "    'on_2b': 4,\n",
    "    'on_3b': 4,\n",
    "\n",
    "    'at_bat_id': 16, \n",
    "    'month': 6,\n",
    "    'score_diff': 8, \n",
    "    'risp': 12, \n",
    "    'clutch': 12,\n",
    "    'blowout': 4, \n",
    "    'post_allstar_break': 4\n",
    "}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Create a mapping from category values to indices\n",
    "    unique_values = df[feature].dropna().unique()\n",
    "    category_maps[feature] = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    \n",
    "    # Use custom dimension if specified, otherwise use 2\n",
    "    if feature in custom_embedding_dims:\n",
    "        embedding_dim = custom_embedding_dims[feature]\n",
    "    else:\n",
    "        # Fallback to heuristic\n",
    "        #embedding_dim = min(50, max(4, int(np.sqrt(len(unique_values)) * 2)))\n",
    "        embedding_dim = 2\n",
    "    \n",
    "    # Store category counts and embedding dimensions\n",
    "    cat_data[feature] = {\n",
    "        'num_categories': len(unique_values) + 1,  # +1 for unknown/padding\n",
    "        'embedding_dim': embedding_dim\n",
    "    }\n",
    "    \n",
    "    # Print some info\n",
    "    print(f\"{feature}: {len(unique_values)} categories, {cat_data[feature]['embedding_dim']} dimensions\")\n",
    "\n",
    "\n",
    "\n",
    "# 5. CONVERT TO PYTORCH TENSORS\n",
    "print(\"Creating tensors...\")\n",
    "# Create a tensor for all continuous features\n",
    "continuous_tensor = torch.tensor(df_cont_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create tensors for categorical features\n",
    "categorical_tensors = {}\n",
    "for feature in categorical_features:\n",
    "    # Map values to indices, using 0 for NaN\n",
    "    indices = [category_maps[feature].get(val, 0) for val in df[feature].fillna('unknown')]\n",
    "    categorical_tensors[feature] = torch.tensor(indices, dtype=torch.long).to(device)\n",
    "\n",
    "# 6. DEFINE MODEL PARAMETERS\n",
    "continuous_dim = len(continuous_features)\n",
    "#output_dim = 256  # Final embedding dimension\n",
    "output_dim = 128  # Final embedding dimension (smaller for prototype)\n",
    "\n",
    "# 7. CREATE EMBEDDING MODEL\n",
    "print(\"Creating embedding model...\")\n",
    "embedding_model = PitchEmbedding(continuous_dim, cat_data, output_dim).to(device)\n",
    "\n",
    "# 8. GENERATE EMBEDDINGS\n",
    "print(\"Generating embeddings...\")\n",
    "with torch.no_grad():  # No need for gradients during inference\n",
    "    pitch_embeddings = embedding_model(continuous_tensor, categorical_tensors)\n",
    "\n",
    "print(f\"Created embeddings with shape: {pitch_embeddings.shape}\")\n",
    "\n",
    "# 9. ORGANIZE INTO AT-BAT SEQUENCES\n",
    "print(\"Organizing into at-bat sequences...\")\n",
    "# Group by at_bat_id\n",
    "unique_at_bats = df['at_bat_id'].unique()\n",
    "print(f\"Total at-bats: {len(unique_at_bats)}\")\n",
    "\n",
    "# Store atbat sequences and their lengths\n",
    "atbat_sequences = []\n",
    "atbat_lengths = []\n",
    "max_seq_len = 0\n",
    "\n",
    "# Process a subset for demonstration (adjust as needed)\n",
    "#sample_at_bats = unique_at_bats[:1000]     #.. (try with only 1000 at-bats for testing)\n",
    "# sample_at_bats = unique_at_bats[:5000]    #.. (try it with more data for more testing)\n",
    "sample_at_bats = unique_at_bats           #.. (use all data for production)\n",
    "\n",
    "\n",
    "for at_bat_id in sample_at_bats:\n",
    "    # Get indices for this at-bat\n",
    "    indices = df[df['at_bat_id'] == at_bat_id].index\n",
    "    \n",
    "    # Get embeddings for these pitches\n",
    "    at_bat_embeddings = pitch_embeddings[indices]\n",
    "    \n",
    "    # Update max sequence length\n",
    "    max_seq_len = max(max_seq_len, len(indices))\n",
    "    \n",
    "    # Store sequence and length\n",
    "    atbat_sequences.append(at_bat_embeddings)\n",
    "    atbat_lengths.append(len(indices))\n",
    "\n",
    "print(f\"Processed {len(atbat_sequences)} at-bat sequences\")\n",
    "print(f\"Average pitches per at-bat: {np.mean(atbat_lengths):.2f}\")\n",
    "print(f\"Maximum sequence length: {max_seq_len}\")\n",
    "\n",
    "# 10. PAD SEQUENCES FOR BATCH PROCESSING\n",
    "print(\"Padding sequences...\")\n",
    "padded_sequences = []\n",
    "attention_mask = []\n",
    "\n",
    "for seq in atbat_sequences:\n",
    "    seq_len = seq.shape[0]\n",
    "    \n",
    "    # Create padded sequence\n",
    "    padded = torch.zeros(max_seq_len, output_dim, device=device)\n",
    "    padded[:seq_len] = seq\n",
    "    \n",
    "    # Create mask (1 for real tokens, 0 for padding)\n",
    "    mask = torch.zeros(max_seq_len, device=device)\n",
    "    mask[:seq_len] = 1\n",
    "    \n",
    "    padded_sequences.append(padded)\n",
    "    attention_mask.append(mask)\n",
    "\n",
    "# Stack into tensors\n",
    "padded_tensor = torch.stack(padded_sequences).to(device)\n",
    "attention_mask = torch.stack(attention_mask).bool().to(device)\n",
    "\n",
    "print(f\"Final tensor shape: {padded_tensor.shape}\")\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "\n",
    "# 11. SAVE FOR LATER USE\n",
    "torch.save({\n",
    "    'embeddings': padded_tensor.cpu(),\n",
    "    'attention_mask': attention_mask.cpu(),\n",
    "    'scaler': scaler,\n",
    "    'category_maps': category_maps\n",
    "}, '../data/embeddings/pitch_embeddings_test_parquet.pt')\n",
    "\n",
    "print(\"Embeddings saved and ready for transformer training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanr\\AppData\\Local\\Temp\\ipykernel_19916\\293898324.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/processed/pitcher_final_2025.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Read your CSV file\n",
    "df = pd.read_csv('../data/processed/pitcher_final_2025.csv')\n",
    "\n",
    "# Convert problematic columns to appropriate types\n",
    "# Convert 'zone' column to numeric, handling any string values\n",
    "df['zone'] = pd.to_numeric(df['zone'], errors='coerce')\n",
    "\n",
    "# Handle other potential problematic columns\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "\t# Try to convert string representations of numbers to actual numeric values\n",
    "\ttry:\n",
    "\t\tdf[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "# Save as Parquet (install pyarrow if needed: pip install pyarrow)\n",
    "df.to_parquet('../data/processed/pitcher_final_2025.parquet', engine='pyarrow')\n",
    "\n",
    "print(\"Conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Normalizing continuous features...\n",
      "Converting categorical features to indices...\n",
      "pitch_type: 0 categories, 16 dimensions\n",
      "batter: 1355 categories, 16 dimensions\n",
      "pitcher: 900 categories, 16 dimensions\n",
      "events: 0 categories, 12 dimensions\n",
      "zone: 13 categories, 6 dimensions\n",
      "game_type: 0 categories, 4 dimensions\n",
      "stand: 0 categories, 4 dimensions\n",
      "p_throws: 0 categories, 4 dimensions\n",
      "home_team: 0 categories, 8 dimensions\n",
      "away_team: 0 categories, 8 dimensions\n",
      "result_type: 0 categories, 4 dimensions\n",
      "hit_location: 9 categories, 6 dimensions\n",
      "bb_type: 0 categories, 8 dimensions\n",
      "balls: 5 categories, 4 dimensions\n",
      "strikes: 4 categories, 4 dimensions\n",
      "game_year: 1 categories, 4 dimensions\n",
      "outs_when_up: 3 categories, 8 dimensions\n",
      "inning: 12 categories, 16 dimensions\n",
      "inning_topbot: 0 categories, 2 dimensions\n",
      "game_pk: 216 categories, 16 dimensions\n",
      "fielder_2: 194 categories, 2 dimensions\n",
      "fielder_3: 234 categories, 2 dimensions\n",
      "fielder_4: 277 categories, 2 dimensions\n",
      "fielder_5: 247 categories, 2 dimensions\n",
      "fielder_6: 212 categories, 2 dimensions\n",
      "fielder_7: 308 categories, 2 dimensions\n",
      "fielder_8: 235 categories, 2 dimensions\n",
      "fielder_9: 285 categories, 2 dimensions\n",
      "pitch_number: 13 categories, 12 dimensions\n",
      "launch_speed_angle: 6 categories, 12 dimensions\n",
      "if_fielding_alignment: 0 categories, 4 dimensions\n",
      "of_fielding_alignment: 0 categories, 4 dimensions\n",
      "n_thruorder_pitcher: 4 categories, 12 dimensions\n",
      "n_priorpa_thisgame_player_at_bat: 7 categories, 12 dimensions\n",
      "on_1b: 1020 categories, 4 dimensions\n",
      "on_2b: 828 categories, 4 dimensions\n",
      "on_3b: 649 categories, 4 dimensions\n",
      "at_bat_id: 16340 categories, 16 dimensions\n",
      "month: 1 categories, 6 dimensions\n",
      "score_diff: 31 categories, 8 dimensions\n",
      "risp: 2 categories, 12 dimensions\n",
      "clutch: 2 categories, 12 dimensions\n",
      "blowout: 2 categories, 4 dimensions\n",
      "post_allstar_break: 1 categories, 4 dimensions\n",
      "Creating tensors...\n",
      "Creating embedding model...\n",
      "Generating embeddings...\n",
      "Created embeddings with shape: torch.Size([63229, 128])\n",
      "Organizing into at-bat sequences...\n",
      "Total at-bats: 16340\n",
      "Processed 16340 at-bat sequences\n",
      "Average pitches per at-bat: 3.87\n",
      "Maximum sequence length: 13\n",
      "Padding sequences...\n",
      "Final tensor shape: torch.Size([16340, 13, 128])\n",
      "Attention mask shape: torch.Size([16340, 13])\n",
      "Embeddings saved and ready for transformer training!\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD PROCESSED DATA\n",
    "print(\"Loading processed data...\")\n",
    "# Use your engineered dataset\n",
    "#df = pd.read_csv('../data/processed/pitcher_final_21-24.parquet')\n",
    "df = pd.read_parquet('../data/processed/pitcher_final_2025.parquet')\n",
    "\n",
    "# 2. DEFINE CONTINUOUS & CATEGORICAL FEATURES\n",
    "continuous_features = [\n",
    "    'release_speed', 'release_pos_x', 'release_pos_z', \n",
    "    'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'hc_x', 'hc_y',\n",
    "    'vx0', 'vy0', 'vz0', 'ax', 'ay', \n",
    "    'az', 'sz_top', 'sz_bot', 'hit_distance_sc', \n",
    "    'launch_speed', 'launch_angle', 'effective_speed', \n",
    "    'release_spin_rate', 'release_extension', \n",
    "    'release_pos_y', 'estimated_ba_using_speedangle',\n",
    "    'estimated_woba_using_speedangle', 'woba_value',\n",
    "    'woba_denom', 'babip_value', 'iso_value', 'spin_axis',\n",
    "    'delta_home_win_exp', 'delta_run_exp', 'bat_speed' ,\n",
    "    'swing_length', 'estimated_slg_using_speedangle',\n",
    "    'delta_pitcher_run_exp', 'hyper_speed',\n",
    "    'bat_win_exp',\n",
    "    'pitcher_days_since_prev_game', \n",
    "    'batter_days_since_prev_game',\n",
    "    'pitcher_days_until_next_game',\n",
    "    'batter_days_until_next_game',\n",
    "    'api_break_z_with_gravity',\n",
    "    'api_break_x_arm',\n",
    "    'api_break_x_batter_in',\n",
    "    'arm_angle', 'home_win_exp',\n",
    "\n",
    "    'at_bat_number', 'bat_score', 'fld_score', 'age_pit', 'age_bat'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'pitch_type', 'batter', 'pitcher', 'events', \n",
    "    #'description', \n",
    "    'zone', \n",
    "    'game_type', 'stand', 'p_throws', 'home_team', 'away_team', \n",
    "    'result_type',\n",
    "    'hit_location', 'bb_type', 'balls', 'strikes', 'game_year',\n",
    "    'outs_when_up', 'inning', 'inning_topbot', 'game_pk',\n",
    "    'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6',\n",
    "    'fielder_7', 'fielder_8', 'fielder_9', \n",
    "    #'at_bat_number', \n",
    "    'pitch_number',\n",
    "    'launch_speed_angle', \n",
    "    #'home_score', 'away_score', \n",
    "    #'bat_score',\n",
    "    #'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', \n",
    "    'if_fielding_alignment', 'of_fielding_alignment',\n",
    "    #'age_pit_legacy', 'age_bat_legacy', \n",
    "    #'age_pit', 'age_bat',\n",
    "    'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat',\n",
    "    #'pitch_name',\n",
    "    'on_1b', 'on_2b', 'on_3b',\n",
    "\n",
    "    'at_bat_id', 'month','score_diff', 'risp', 'clutch', 'blowout', 'post_allstar_break'\n",
    "]\n",
    "\n",
    "\n",
    "# 3. NORMALIZE CONTINUOUS FEATURES\n",
    "print(\"Normalizing continuous features...\")\n",
    "scaler = StandardScaler()\n",
    "df_cont = df[continuous_features].copy()\n",
    "# Handle any remaining NaNs\n",
    "df_cont = df_cont.fillna(0)\n",
    "df_cont_scaled = scaler.fit_transform(df_cont)\n",
    "\n",
    "# 4. CREATE CATEGORY MAPPINGS & CONVERT TO INDICES\n",
    "print(\"Converting categorical features to indices...\")\n",
    "category_maps = {}\n",
    "cat_data = {}\n",
    "\n",
    "# Define custom embedding dimensions for important features\n",
    "# Format: 'feature_name': desired_embedding_dimension\n",
    "custom_embedding_dims = {\n",
    "    'pitch_type': 16, \n",
    "    'batter': 16, \n",
    "    'pitcher': 16, \n",
    "    'events': 12, \n",
    "    #'description', \n",
    "    'zone': 6, \n",
    "    'game_type': 4, \n",
    "    'stand': 4, \n",
    "    'p_throws': 4, \n",
    "    'home_team': 8, \n",
    "    'away_team': 8, \n",
    "    'result_type': 4,\n",
    "    'hit_location': 6, \n",
    "    'bb_type': 8, \n",
    "    'balls': 4, \n",
    "    'strikes': 4, \n",
    "    'game_year': 4,\n",
    "    'outs_when_up': 8, \n",
    "    'inning': 16, \n",
    "    'inning_topbot': 2, \n",
    "    'game_pk': 16,\n",
    "    #'fielder_2':, \n",
    "    #'fielder_3':, \n",
    "    #'fielder_4':, \n",
    "    #'fielder_5':, \n",
    "    #'fielder_6':,\n",
    "    #'fielder_7':, \n",
    "    #'fielder_8':, \n",
    "    #'fielder_9':, \n",
    "    ####'at_bat_number': 12, \n",
    "    'pitch_number': 12,\n",
    "    'launch_speed_angle': 12, \n",
    "    #'home_score', \n",
    "    #'away_score', \n",
    "    ####'bat_score': 16,\n",
    "    ####'fld_score': 16, \n",
    "    #'post_away_score', \n",
    "    #'post_home_score', \n",
    "    #'post_bat_score',\n",
    "    #'post_fld_score', \n",
    "    'if_fielding_alignment': 4, \n",
    "    'of_fielding_alignment': 4,\n",
    "    #'age_pit_legacy', \n",
    "    #'age_bat_legacy', \n",
    "    ####'age_pit': 8, \n",
    "    ####'age_bat': 8,\n",
    "    'n_thruorder_pitcher': 12, \n",
    "    'n_priorpa_thisgame_player_at_bat': 12,\n",
    "    #'pitch_name',\n",
    "    \n",
    "    'on_1b': 4,\n",
    "    'on_2b': 4,\n",
    "    'on_3b': 4,\n",
    "\n",
    "    'at_bat_id': 16, \n",
    "    'month': 6,\n",
    "    'score_diff': 8, \n",
    "    'risp': 12, \n",
    "    'clutch': 12,\n",
    "    'blowout': 4, \n",
    "    'post_allstar_break': 4\n",
    "}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Create a mapping from category values to indices\n",
    "    unique_values = df[feature].dropna().unique()\n",
    "    category_maps[feature] = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    \n",
    "    # Use custom dimension if specified, otherwise use 2\n",
    "    if feature in custom_embedding_dims:\n",
    "        embedding_dim = custom_embedding_dims[feature]\n",
    "    else:\n",
    "        # Fallback to heuristic\n",
    "        #embedding_dim = min(50, max(4, int(np.sqrt(len(unique_values)) * 2)))\n",
    "        embedding_dim = 2\n",
    "    \n",
    "    # Store category counts and embedding dimensions\n",
    "    cat_data[feature] = {\n",
    "        'num_categories': len(unique_values) + 1,  # +1 for unknown/padding\n",
    "        'embedding_dim': embedding_dim\n",
    "    }\n",
    "    \n",
    "    # Print some info\n",
    "    print(f\"{feature}: {len(unique_values)} categories, {cat_data[feature]['embedding_dim']} dimensions\")\n",
    "\n",
    "\n",
    "\n",
    "# 5. CONVERT TO PYTORCH TENSORS\n",
    "print(\"Creating tensors...\")\n",
    "# Create a tensor for all continuous features\n",
    "continuous_tensor = torch.tensor(df_cont_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create tensors for categorical features\n",
    "categorical_tensors = {}\n",
    "for feature in categorical_features:\n",
    "    # Map values to indices, using 0 for NaN\n",
    "    indices = [category_maps[feature].get(val, 0) for val in df[feature].fillna('unknown')]\n",
    "    categorical_tensors[feature] = torch.tensor(indices, dtype=torch.long).to(device)\n",
    "\n",
    "# 6. DEFINE MODEL PARAMETERS\n",
    "continuous_dim = len(continuous_features)\n",
    "#output_dim = 256  # Final embedding dimension\n",
    "output_dim = 128  # Final embedding dimension (smaller for prototype)\n",
    "\n",
    "# 7. CREATE EMBEDDING MODEL\n",
    "print(\"Creating embedding model...\")\n",
    "embedding_model = PitchEmbedding(continuous_dim, cat_data, output_dim).to(device)\n",
    "\n",
    "# 8. GENERATE EMBEDDINGS\n",
    "print(\"Generating embeddings...\")\n",
    "with torch.no_grad():  # No need for gradients during inference\n",
    "    pitch_embeddings = embedding_model(continuous_tensor, categorical_tensors)\n",
    "\n",
    "print(f\"Created embeddings with shape: {pitch_embeddings.shape}\")\n",
    "\n",
    "# 9. ORGANIZE INTO AT-BAT SEQUENCES\n",
    "print(\"Organizing into at-bat sequences...\")\n",
    "# Group by at_bat_id\n",
    "unique_at_bats = df['at_bat_id'].unique()\n",
    "print(f\"Total at-bats: {len(unique_at_bats)}\")\n",
    "\n",
    "# Store atbat sequences and their lengths\n",
    "atbat_sequences = []\n",
    "atbat_lengths = []\n",
    "max_seq_len = 0\n",
    "\n",
    "# Process a subset for demonstration (adjust as needed)\n",
    "#sample_at_bats = unique_at_bats[:1000]     #.. (try with only 1000 at-bats for testing)\n",
    "# sample_at_bats = unique_at_bats[:5000]    #.. (try it with more data for more testing)\n",
    "sample_at_bats = unique_at_bats           #.. (use all data for production)\n",
    "\n",
    "\n",
    "for at_bat_id in sample_at_bats:\n",
    "    # Get indices for this at-bat\n",
    "    indices = df[df['at_bat_id'] == at_bat_id].index\n",
    "    \n",
    "    # Get embeddings for these pitches\n",
    "    at_bat_embeddings = pitch_embeddings[indices]\n",
    "    \n",
    "    # Update max sequence length\n",
    "    max_seq_len = max(max_seq_len, len(indices))\n",
    "    \n",
    "    # Store sequence and length\n",
    "    atbat_sequences.append(at_bat_embeddings)\n",
    "    atbat_lengths.append(len(indices))\n",
    "\n",
    "print(f\"Processed {len(atbat_sequences)} at-bat sequences\")\n",
    "print(f\"Average pitches per at-bat: {np.mean(atbat_lengths):.2f}\")\n",
    "print(f\"Maximum sequence length: {max_seq_len}\")\n",
    "\n",
    "# 10. PAD SEQUENCES FOR BATCH PROCESSING\n",
    "print(\"Padding sequences...\")\n",
    "padded_sequences = []\n",
    "attention_mask = []\n",
    "\n",
    "for seq in atbat_sequences:\n",
    "    seq_len = seq.shape[0]\n",
    "    \n",
    "    # Create padded sequence\n",
    "    padded = torch.zeros(max_seq_len, output_dim, device=device)\n",
    "    padded[:seq_len] = seq\n",
    "    \n",
    "    # Create mask (1 for real tokens, 0 for padding)\n",
    "    mask = torch.zeros(max_seq_len, device=device)\n",
    "    mask[:seq_len] = 1\n",
    "    \n",
    "    padded_sequences.append(padded)\n",
    "    attention_mask.append(mask)\n",
    "\n",
    "# Stack into tensors\n",
    "padded_tensor = torch.stack(padded_sequences).to(device)\n",
    "attention_mask = torch.stack(attention_mask).bool().to(device)\n",
    "\n",
    "print(f\"Final tensor shape: {padded_tensor.shape}\")\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "\n",
    "# 11. SAVE FOR LATER USE\n",
    "torch.save({\n",
    "    'embeddings': padded_tensor.cpu(),\n",
    "    'attention_mask': attention_mask.cpu(),\n",
    "    'scaler': scaler,\n",
    "    'category_maps': category_maps\n",
    "}, '../data/embeddings/pitch_embeddings_2025_parquet.pt')\n",
    "\n",
    "print(\"Embeddings saved and ready for transformer training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_baseball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
